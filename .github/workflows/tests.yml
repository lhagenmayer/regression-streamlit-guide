name: Comprehensive Testing Suite

on:
  push:
    branches: [ master, main, develop ]
  pull_request:
    branches: [ master, main, develop ]
  workflow_dispatch:
    inputs:
      test_types:
        description: 'Test types to run (comma-separated: unit,integration,performance,property,visual)'
        required: false
        default: 'unit,integration'
      python_versions:
        description: 'Python versions to test (comma-separated)'
        required: false
        default: '3.9,3.10,3.11,3.12'

env:
  PYTHONUNBUFFERED: 1
  PYTHONDONTWRITEBYTECODE: 1

jobs:
  # ====================================================================
  # SECURITY & DEPENDENCY CHECKS
  # ====================================================================

  security-check:
    name: Security & Dependencies
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.12"
        cache: 'pip'

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-security-${{ hashFiles('requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-security-

    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install safety bandit[toml] pip-audit

    - name: Check for known security vulnerabilities
      run: |
        echo "ğŸ” Checking for known security vulnerabilities..."
        safety check --file requirements.txt --output json || true
        safety check --file requirements-dev.txt --output json || true

    - name: Run Bandit security linter
      run: |
        echo "ğŸ›¡ï¸ Running Bandit security analysis..."
        bandit -r src/ -f json -o bandit-report.json || true

    - name: Check for dependency updates
      run: |
        echo "ğŸ“¦ Checking for outdated dependencies..."
        pip list --outdated --format=json || true

    - name: Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json

  # ====================================================================
  # PYTHON VERSION MATRIX TESTING
  # ====================================================================

  test-matrix:
    name: Test Matrix (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    needs: security-check
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.9", "3.10", "3.11", "3.12"]
        include:
          - python-version: "3.12"
            is_main: true

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
        cache-dependency-path: |
          requirements*.txt
          pyproject.toml

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y graphviz  # For documentation generation

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip install -r requirements.txt -r requirements-dev.txt
        pip install pytest-cov pytest-xdist pytest-benchmark

    - name: Cache test data
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pytest
          .pytest_cache
        key: ${{ runner.os }}-pytest-${{ matrix.python-version }}-${{ hashFiles('tests/**') }}
        restore-keys: |
          ${{ runner.os }}-pytest-${{ matrix.python-version }}-
          ${{ runner.os }}-pytest-

    - name: Run syntax and import checks
      run: |
        echo "ğŸ” Running syntax and import validation..."
        python -m py_compile run.py
        python -c "import sys; sys.path.insert(0, 'src'); import config, data, content, plots, logger, accessibility; print('âœ… All imports successful')"

    - name: Validate modular architecture
      run: |
        echo "ğŸ—ï¸ Validating modular architecture..."
        python scripts/validate_architecture.py

    - name: Run unit tests
      run: |
        echo "ğŸ§ª Running unit tests..."
        python -m pytest tests/test_data.py tests/test_plots.py tests/test_logging.py tests/test_accessibility.py tests/test_modular_separation.py \
          -v --tb=short --durations=10 \
          --cov=src --cov-report=xml --cov-report=term-missing \
          --junitxml=test-results-unit-${{ matrix.python-version }}.xml

    - name: Run integration tests
      run: |
        echo "ğŸ”— Running integration tests..."
        python -m pytest tests/test_app_integration.py \
          -v --tb=short --durations=10 \
          --junitxml=test-results-integration-${{ matrix.python-version }}.xml \
          -m "not slow"

    - name: Run performance tests
      run: |
        echo "âš¡ Running performance tests..."
        python -m pytest tests/test_performance.py \
          -v --tb=short --durations=10 \
          --junitxml=test-results-performance-${{ matrix.python-version }}.xml \
          -m "performance and not slow"

    - name: Generate test report
      if: always()
      run: |
        echo "## Test Results (Python ${{ matrix.python-version }})" >> test-report-${{ matrix.python-version }}.md
        echo "" >> test-report-${{ matrix.python-version }}.md
        echo "### Test Summary" >> test-report-${{ matrix.python-version }}.md
        echo "\`\`\`" >> test-report-${{ matrix.python-version }}.md
        python -m pytest --collect-only tests/ | grep -E "(test_|::)" | wc -l | xargs echo "Collected tests:" >> test-report-${{ matrix.python-version }}.md
        echo "\`\`\`" >> test-report-${{ matrix.python-version }}.md
        echo "" >> test-report-${{ matrix.python-version }}.md

    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-py${{ matrix.python-version }}
        path: |
          test-results-*.xml
          test-report-*.md
          coverage.xml

    - name: Upload coverage to Codecov
      if: matrix.is_main == true
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        flags: python${{ matrix.python-version }}
        name: codecov-python${{ matrix.python-version }}
        fail_ci_if_error: false

  # ====================================================================
  # COMPREHENSIVE TEST SUITE
  # ====================================================================

  test-comprehensive:
    name: Comprehensive Test Suite
    runs-on: ubuntu-latest
    needs: test-matrix
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.12"
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt -r requirements-dev.txt
        pip install pytest-cov pytest-xdist pytest-benchmark

    - name: Run comprehensive test suite
      run: |
        echo "ğŸš€ Running comprehensive test suite..."
        python -m pytest tests/ \
          -v --tb=short --durations=20 \
          --maxfail=5 \
          --cov=src --cov-report=xml --cov-report=html --cov-report=term-missing \
          --cov-fail-under=95 \
          --junitxml=comprehensive-test-results.xml

    - name: Generate comprehensive report
      if: always()
      run: |
        echo "# Comprehensive Test Report" > comprehensive-report.md
        echo "" >> comprehensive-report.md
        echo "## Execution Summary" >> comprehensive-report.md
        echo "- **Date**: $(date)" >> comprehensive-report.md
        echo "- **Branch**: ${GITHUB_REF#refs/heads/}" >> comprehensive-report.md
        echo "- **Commit**: ${GITHUB_SHA::8}" >> comprehensive-report.md
        echo "" >> comprehensive-report.md
        echo "## Coverage Summary" >> comprehensive-report.md
        echo "\`\`\`" >> comprehensive-report.md
        coverage report --show-missing | tail -20 >> comprehensive-report.md
        echo "\`\`\`" >> comprehensive-report.md

    - name: Upload comprehensive results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: comprehensive-test-results
        path: |
          comprehensive-test-results.xml
          comprehensive-report.md
          htmlcov/
          coverage.xml

  # ====================================================================
  # PERFORMANCE & REGRESSION TESTING
  # ====================================================================

  performance-regression:
    name: Performance Regression Tests
    runs-on: ubuntu-latest
    needs: security-check
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.12"
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt -r requirements-dev.txt
        pip install pytest-benchmark

    - name: Run performance benchmarks
      run: |
        echo "âš¡ Running performance benchmarks..."
        python -m pytest tests/test_performance.py \
          -v --tb=short --benchmark-only \
          --benchmark-save=performance-${GITHUB_SHA::8} \
          --benchmark-save-data \
          --junitxml=performance-results.xml

    - name: Compare performance against baseline
      run: |
        echo "ğŸ“Š Comparing performance against baseline..."
        # This would compare against stored baseline in future
        echo "Performance test completed - baseline comparison would go here"

    - name: Upload performance results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-results
        path: |
          performance-results.xml
          .benchmarks/

  # ====================================================================
  # CROSS-PLATFORM COMPATIBILITY
  # ====================================================================

  test-cross-platform:
    name: Cross-Platform Tests (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    needs: security-check
    if: github.event_name == 'workflow_dispatch'
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        include:
          - os: ubuntu-latest
            python-version: "3.11"
          - os: windows-latest
            python-version: "3.11"
          - os: macos-latest
            python-version: "3.11"

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt -r requirements-dev.txt

    - name: Run cross-platform tests
      run: |
        echo "ğŸŒ Running cross-platform tests on ${{ matrix.os }}..."
        python -c "
        import sys
        sys.path.insert(0, 'src')
        import config, data, content, plots, logger, accessibility
        from data import generate_simple_regression_data
        result = generate_simple_regression_data('ğŸ‡¨ğŸ‡­ Schweizer Kantone (sozioÃ¶konomisch)', 'Population Density', 5, 42)
        assert 'x' in result and 'y' in result
        print('âœ… Cross-platform compatibility verified')
        "

    - name: Run basic test suite
      run: |
        python -m pytest tests/test_data.py -v --tb=short -x

  # ====================================================================
  # FINAL REPORTING & NOTIFICATIONS
  # ====================================================================

  test-summary:
    name: Test Summary & Reporting
    runs-on: ubuntu-latest
    needs: [security-check, test-matrix, test-comprehensive, performance-regression]
    if: always()

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Download test artifacts
      uses: actions/download-artifact@v4
      with:
        path: artifacts/

    - name: Generate final test report
      run: |
        echo "# Linear Regression Guide - Test Summary" > final-test-report.md
        echo "" >> final-test-report.md
        echo "## Execution Overview" >> final-test-report.md
        echo "- **Workflow**: ${{ github.workflow }}" >> final-test-report.md
        echo "- **Run ID**: ${{ github.run_id }}" >> final-test-report.md
        echo "- **Triggered by**: ${{ github.event_name }}" >> final-test-report.md
        echo "- **Branch**: ${{ github.ref_name }}" >> final-test-report.md
        echo "- **Commit**: ${{ github.sha }}" >> final-test-report.md
        echo "" >> final-test-report.md

        # Count test results
        if [ -d "artifacts/" ]; then
          echo "## Test Results Summary" >> final-test-report.md
          find artifacts/ -name "*.xml" -exec echo "- {}" \; >> final-test-report.md
          echo "" >> final-test-report.md
        fi

        echo "## Job Status Summary" >> final-test-report.md
        echo "- Security Check: ${{ needs.security-check.result }}" >> final-test-report.md
        echo "- Test Matrix: ${{ needs.test-matrix.result }}" >> final-test-report.md
        echo "- Comprehensive Tests: ${{ needs.test-comprehensive.result }}" >> final-test-report.md
        echo "- Performance Tests: ${{ needs.performance-regression.result }}" >> final-test-report.md
        echo "" >> final-test-report.md

        # Overall status
        if [ "${{ needs.security-check.result }}" = "success" ] && \
           [ "${{ needs.test-matrix.result }}" = "success" ] && \
           [ "${{ needs.test-comprehensive.result }}" = "success" ]; then
          echo "## âœ… Overall Status: PASSED" >> final-test-report.md
          echo "All tests completed successfully!" >> final-test-report.md
        else
          echo "## âŒ Overall Status: FAILED" >> final-test-report.md
          echo "Some tests failed - check individual job logs for details." >> final-test-report.md
        fi

    - name: Upload final report
      uses: actions/upload-artifact@v4
      with:
        name: final-test-report
        path: final-test-report.md

    - name: Test completion notification
      if: always()
      run: |
        if [ "${{ needs.security-check.result }}" = "success" ] && \
           [ "${{ needs.test-matrix.result }}" = "success" ] && \
           [ "${{ needs.test-comprehensive.result }}" = "success" ]; then
          echo "ğŸ‰ All tests passed! The codebase is ready for deployment."
        else
          echo "âš ï¸ Some tests failed. Please review the test results and fix any issues."
        fi
